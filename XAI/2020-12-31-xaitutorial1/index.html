
<!doctype html>
<html lang="en" class="no-js">
  <head>
    
      <meta charset="utf-8">
      <meta name="viewport" content="width=device-width,initial-scale=1">
      
      
      
        <link rel="canonical" href="https://simonjisu.github.io/PaperReading/XAI/2020-12-31-xaitutorial1/">
      
      <link rel="icon" href="../../assets/images/favicon.png">
      <meta name="generator" content="mkdocs-1.3.0, mkdocs-material-8.3.9">
    
    
      
        <title>Explainable Artificial Intelligence (XAI) - 1 - Soopace - Paper Reading</title>
      
    
    
      <link rel="stylesheet" href="../../assets/stylesheets/main.1d29e8d0.min.css">
      
        
        <link rel="stylesheet" href="../../assets/stylesheets/palette.cbb835fc.min.css">
        
          
          
          <meta name="theme-color" content="#4051b5">
        
      
      
    
    
    
      
        
        
        <link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
        <link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Roboto:300,300i,400,400i,700,700i%7CRoboto+Mono:400,400i,700,700i&display=fallback">
        <style>:root{--md-text-font:"Roboto";--md-code-font:"Roboto Mono"}</style>
      
    
    
      <link rel="stylesheet" href="../../stylesheets/extra.css">
    
    <script>__md_scope=new URL("../..",location),__md_get=(e,_=localStorage,t=__md_scope)=>JSON.parse(_.getItem(t.pathname+"."+e)),__md_set=(e,_,t=localStorage,a=__md_scope)=>{try{t.setItem(a.pathname+"."+e,JSON.stringify(_))}catch(e){}}</script>
    
      

    
    
  </head>
  
  
    
    
    
    
    
    <body dir="ltr" data-md-color-scheme="" data-md-color-primary="indigo" data-md-color-accent="">
  
    
    
    <input class="md-toggle" data-md-toggle="drawer" type="checkbox" id="__drawer" autocomplete="off">
    <input class="md-toggle" data-md-toggle="search" type="checkbox" id="__search" autocomplete="off">
    <label class="md-overlay" for="__drawer"></label>
    <div data-md-component="skip">
      
        
        <a href="#explainable-artificial-intelligence-xai-1" class="md-skip">
          Skip to content
        </a>
      
    </div>
    <div data-md-component="announce">
      
    </div>
    
    
      

<header class="md-header" data-md-component="header">
  <nav class="md-header__inner md-grid" aria-label="Header">
    <a href="../.." title="Soopace - Paper Reading" class="md-header__button md-logo" aria-label="Soopace - Paper Reading" data-md-component="logo">
      
  <img src="../../img/logo/logo.png" alt="logo">

    </a>
    <label class="md-header__button md-icon" for="__drawer">
      <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M3 6h18v2H3V6m0 5h18v2H3v-2m0 5h18v2H3v-2Z"/></svg>
    </label>
    <div class="md-header__title" data-md-component="header-title">
      <div class="md-header__ellipsis">
        <div class="md-header__topic">
          <span class="md-ellipsis">
            Soopace - Paper Reading
          </span>
        </div>
        <div class="md-header__topic" data-md-component="header-topic">
          <span class="md-ellipsis">
            
              Explainable Artificial Intelligence (XAI) - 1
            
          </span>
        </div>
      </div>
    </div>
    
    
    
      <label class="md-header__button md-icon" for="__search">
        <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M9.5 3A6.5 6.5 0 0 1 16 9.5c0 1.61-.59 3.09-1.56 4.23l.27.27h.79l5 5-1.5 1.5-5-5v-.79l-.27-.27A6.516 6.516 0 0 1 9.5 16 6.5 6.5 0 0 1 3 9.5 6.5 6.5 0 0 1 9.5 3m0 2C7 5 5 7 5 9.5S7 14 9.5 14 14 12 14 9.5 12 5 9.5 5Z"/></svg>
      </label>
      <div class="md-search" data-md-component="search" role="dialog">
  <label class="md-search__overlay" for="__search"></label>
  <div class="md-search__inner" role="search">
    <form class="md-search__form" name="search">
      <input type="text" class="md-search__input" name="query" aria-label="Search" placeholder="Search" autocapitalize="off" autocorrect="off" autocomplete="off" spellcheck="false" data-md-component="search-query" required>
      <label class="md-search__icon md-icon" for="__search">
        <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M9.5 3A6.5 6.5 0 0 1 16 9.5c0 1.61-.59 3.09-1.56 4.23l.27.27h.79l5 5-1.5 1.5-5-5v-.79l-.27-.27A6.516 6.516 0 0 1 9.5 16 6.5 6.5 0 0 1 3 9.5 6.5 6.5 0 0 1 9.5 3m0 2C7 5 5 7 5 9.5S7 14 9.5 14 14 12 14 9.5 12 5 9.5 5Z"/></svg>
        <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M20 11v2H8l5.5 5.5-1.42 1.42L4.16 12l7.92-7.92L13.5 5.5 8 11h12Z"/></svg>
      </label>
      <nav class="md-search__options" aria-label="Search">
        
        <button type="reset" class="md-search__icon md-icon" aria-label="Clear" tabindex="-1">
          <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M19 6.41 17.59 5 12 10.59 6.41 5 5 6.41 10.59 12 5 17.59 6.41 19 12 13.41 17.59 19 19 17.59 13.41 12 19 6.41Z"/></svg>
        </button>
      </nav>
      
    </form>
    <div class="md-search__output">
      <div class="md-search__scrollwrap" data-md-scrollfix>
        <div class="md-search-result" data-md-component="search-result">
          <div class="md-search-result__meta">
            Initializing search
          </div>
          <ol class="md-search-result__list"></ol>
        </div>
      </div>
    </div>
  </div>
</div>
    
    
      <div class="md-header__source">
        <a href="https://github.com/simonjisu/PaperReading" title="Go to repository" class="md-source" data-md-component="source">
  <div class="md-source__icon md-icon">
    
    <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 448 512"><!--! Font Awesome Free 6.1.1 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free (Icons: CC BY 4.0, Fonts: SIL OFL 1.1, Code: MIT License) Copyright 2022 Fonticons, Inc.--><path d="M439.55 236.05 244 40.45a28.87 28.87 0 0 0-40.81 0l-40.66 40.63 51.52 51.52c27.06-9.14 52.68 16.77 43.39 43.68l49.66 49.66c34.23-11.8 61.18 31 35.47 56.69-26.49 26.49-70.21-2.87-56-37.34L240.22 199v121.85c25.3 12.54 22.26 41.85 9.08 55a34.34 34.34 0 0 1-48.55 0c-17.57-17.6-11.07-46.91 11.25-56v-123c-20.8-8.51-24.6-30.74-18.64-45L142.57 101 8.45 235.14a28.86 28.86 0 0 0 0 40.81l195.61 195.6a28.86 28.86 0 0 0 40.8 0l194.69-194.69a28.86 28.86 0 0 0 0-40.81z"/></svg>
  </div>
  <div class="md-source__repository">
    GitHub
  </div>
</a>
      </div>
    
  </nav>
  
</header>
    
    <div class="md-container" data-md-component="container">
      
      
        
          
        
      
      <main class="md-main" data-md-component="main">
        <div class="md-main__inner md-grid">
          
            
              
              <div class="md-sidebar md-sidebar--primary" data-md-component="sidebar" data-md-type="navigation" >
                <div class="md-sidebar__scrollwrap">
                  <div class="md-sidebar__inner">
                    


<nav class="md-nav md-nav--primary" aria-label="Navigation" data-md-level="0">
  <label class="md-nav__title" for="__drawer">
    <a href="../.." title="Soopace - Paper Reading" class="md-nav__button md-logo" aria-label="Soopace - Paper Reading" data-md-component="logo">
      
  <img src="../../img/logo/logo.png" alt="logo">

    </a>
    Soopace - Paper Reading
  </label>
  
    <div class="md-nav__source">
      <a href="https://github.com/simonjisu/PaperReading" title="Go to repository" class="md-source" data-md-component="source">
  <div class="md-source__icon md-icon">
    
    <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 448 512"><!--! Font Awesome Free 6.1.1 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free (Icons: CC BY 4.0, Fonts: SIL OFL 1.1, Code: MIT License) Copyright 2022 Fonticons, Inc.--><path d="M439.55 236.05 244 40.45a28.87 28.87 0 0 0-40.81 0l-40.66 40.63 51.52 51.52c27.06-9.14 52.68 16.77 43.39 43.68l49.66 49.66c34.23-11.8 61.18 31 35.47 56.69-26.49 26.49-70.21-2.87-56-37.34L240.22 199v121.85c25.3 12.54 22.26 41.85 9.08 55a34.34 34.34 0 0 1-48.55 0c-17.57-17.6-11.07-46.91 11.25-56v-123c-20.8-8.51-24.6-30.74-18.64-45L142.57 101 8.45 235.14a28.86 28.86 0 0 0 0 40.81l195.61 195.6a28.86 28.86 0 0 0 40.8 0l194.69-194.69a28.86 28.86 0 0 0 0-40.81z"/></svg>
  </div>
  <div class="md-source__repository">
    GitHub
  </div>
</a>
    </div>
  
  <ul class="md-nav__list" data-md-scrollfix>
    
      
      
      

  
  
  
    <li class="md-nav__item">
      <a href="../.." class="md-nav__link">
        Welcome
      </a>
    </li>
  

    
      
      
      

  
  
    
  
  
    
    <li class="md-nav__item md-nav__item--active md-nav__item--nested">
      
      
        <input class="md-nav__toggle md-toggle" data-md-toggle="__nav_2" type="checkbox" id="__nav_2" checked>
      
      
      
      
        
        
        <div class="md-nav__link md-nav__link--index ">
          <a href="../">XAI</a>
          
            <label for="__nav_2">
              <span class="md-nav__icon md-icon"></span>
            </label>
          
        </div>
      
      <nav class="md-nav" aria-label="XAI" data-md-level="1">
        <label class="md-nav__title" for="__nav_2">
          <span class="md-nav__icon md-icon"></span>
          XAI
        </label>
        <ul class="md-nav__list" data-md-scrollfix>
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../2019-09-18-introxai/" class="md-nav__link">
        Explaining Explanations: An Overview of Interpretability of Machine Learning
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../2020-07-23-casm/" class="md-nav__link">
        Classifier-agnostic saliency map extraction
      </a>
    </li>
  

            
          
            
              
  
  
    
  
  
    <li class="md-nav__item md-nav__item--active">
      
      <input class="md-nav__toggle md-toggle" data-md-toggle="toc" type="checkbox" id="__toc">
      
      
        
      
      
      <a href="./" class="md-nav__link md-nav__link--active">
        Explainable Artificial Intelligence (XAI) - 1
      </a>
      
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../2021-01-14-xaitutorial2/" class="md-nav__link">
        Explainable Artificial Intelligence (XAI) - 2
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../2021-11-21-nbdt/" class="md-nav__link">
        NBDT: Neural-Backed Decision Trees
      </a>
    </li>
  

            
          
        </ul>
      </nav>
    </li>
  

    
      
      
      

  
  
  
    
    <li class="md-nav__item md-nav__item--nested">
      
      
        <input class="md-nav__toggle md-toggle" data-md-toggle="__nav_3" type="checkbox" id="__nav_3" >
      
      
      
      
        
        
        <div class="md-nav__link md-nav__link--index ">
          <a href="../../NLP/">NLP</a>
          
            <label for="__nav_3">
              <span class="md-nav__icon md-icon"></span>
            </label>
          
        </div>
      
      <nav class="md-nav" aria-label="NLP" data-md-level="1">
        <label class="md-nav__title" for="__nav_3">
          <span class="md-nav__icon md-icon"></span>
          NLP
        </label>
        <ul class="md-nav__list" data-md-scrollfix>
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../NLP/2017-08-04-E2EMN/" class="md-nav__link">
        End-to-End Memory Network
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../NLP/2018-04-04-nsmcbidreclstmselfattn/" class="md-nav__link">
        A Structured Self-Attentive Sentence Embedding
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../NLP/2018-08-22-neuralnetworklm/" class="md-nav__link">
        A Neural Probabilistic Language Model
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../NLP/2020-01-14-attentionisallyouneed/" class="md-nav__link">
        Attention Is All You Need - 1
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../NLP/2020-02-02-attentionisallyouneed2/" class="md-nav__link">
        Attention Is All You Need - 2
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../NLP/2020-02-23-attentionisallyouneed3/" class="md-nav__link">
        Attention Is All You Need - 3
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../NLP/2020-07-19-maskpredict/" class="md-nav__link">
        Mask-Predict: Parallel Decoding of Conditional Masked Language Models
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../NLP/2021-08-13-hybridranking/" class="md-nav__link">
        Hybrid Ranking Network for Text-to-SQL
      </a>
    </li>
  

            
          
        </ul>
      </nav>
    </li>
  

    
      
      
      

  
  
  
    
    <li class="md-nav__item md-nav__item--nested">
      
      
        <input class="md-nav__toggle md-toggle" data-md-toggle="__nav_4" type="checkbox" id="__nav_4" >
      
      
      
      
        
        
        <div class="md-nav__link md-nav__link--index ">
          <a href="../../VISION/">VISION</a>
          
            <label for="__nav_4">
              <span class="md-nav__icon md-icon"></span>
            </label>
          
        </div>
      
      <nav class="md-nav" aria-label="VISION" data-md-level="1">
        <label class="md-nav__title" for="__nav_4">
          <span class="md-nav__icon md-icon"></span>
          VISION
        </label>
        <ul class="md-nav__list" data-md-scrollfix>
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../VISION/2020-03-12-deepinsidecnn/" class="md-nav__link">
        Deep Inside Convolutional Networks: Visualising Image Classification Models and Saliency Maps
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../VISION/2021-04-20-featurevisualization/" class="md-nav__link">
        Feature Visualization
      </a>
    </li>
  

            
          
        </ul>
      </nav>
    </li>
  

    
  </ul>
</nav>
                  </div>
                </div>
              </div>
            
            
              
              <div class="md-sidebar md-sidebar--secondary" data-md-component="sidebar" data-md-type="toc" >
                <div class="md-sidebar__scrollwrap">
                  <div class="md-sidebar__inner">
                    

<nav class="md-nav md-nav--secondary" aria-label="Table of contents">
  
  
  
    
  
  
</nav>
                  </div>
                </div>
              </div>
            
          
          <div class="md-content" data-md-component="content">
            <article class="md-content__inner md-typeset">
              
  
                
  <a href="https://github.com/simonjisu/PaperReading/edit/master/docs/XAI/2020-12-31-xaitutorial1.md" title="Edit this page" class="md-content__button md-icon">
    <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M20.71 7.04c.39-.39.39-1.04 0-1.41l-2.34-2.34c-.37-.39-1.02-.39-1.41 0l-1.84 1.83 3.75 3.75M3 17.25V21h3.75L17.81 9.93l-3.75-3.75L3 17.25Z"/></svg>
  </a>


  



<h1 id="explainable-artificial-intelligence-xai-1">Explainable Artificial Intelligence (XAI) - 1<a class="headerlink" href="#explainable-artificial-intelligence-xai-1" title="Permanent link">&para;</a></h1>
<h1 id="explainable-artificial-intelligence-xai-concepts-taxonomies-opportunities-and-challenges-toward-responsible-ai">Explainable Artificial Intelligence (XAI): Concepts, taxonomies, opportunities and challenges toward responsible AI<a class="headerlink" href="#explainable-artificial-intelligence-xai-concepts-taxonomies-opportunities-and-challenges-toward-responsible-ai" title="Permanent link">&para;</a></h1>
<p>Paper Link: <a href="https://arxiv.org/abs/1910.10045">https://arxiv.org/abs/1910.10045</a></p>
<p>XAIì— ëŒ€í•œ ì „ë°˜ì ì¸ ì†Œê°œë¥¼ ì •ë¦¬í•œ ë…¼ë¬¸ì´ ë‚˜ì™€ì„œ ì°¨ê·¼ ì°¨ê·¼ ìš”ì•½ ì •ë¦¬í•´ë³´ë ¤ê³  í•œë‹¤(ë¬´ë ¤ 115í˜ì´ì§€, referenceë§Œ 6í˜ì´ì§€). ì•½ê°„ì˜ ë²ˆì—­ ì–´íˆ¬ì™€ ìƒëµëœ ê²ƒë„ ìˆìœ¼ë‹ˆ ì˜ì–´ ì›ë¬¸ì„ ì°¸ê³ í•˜ê¸¸ ë°”ë€ë‹¤.</p>
<ol>
<li><a href="https://simonjisu.github.io/paper/2020/12/31/xaitutorial1.html"><span style="color:#e25252">Introduction(ì´ë²ˆí¸)</span></a></li>
<li><a href="https://simonjisu.github.io/paper/2021/01/14/xaitutorial2.html">Explainability: What, why, what for and how?</a></li>
<li><a href="https://simonjisu.github.io/paper/2021/01/23/xaitutorial3.html">Transparent machine learning models</a></li>
<li>Post-hoc explainability techniques for machile learning models: Taxonomy, shallow models and deep learning</li>
<li>XAI: Opportunities, challenges and future research needs</li>
<li>Toward responsible AI: Principles of artificial intelligence, fairness, privacy and data fusion</li>
<li>Conclusions and outlook</li>
</ol>
<h1 id="1-introduction">1. Introduction<a class="headerlink" href="#1-introduction" title="Permanent link">&para;</a></h1>
<p>[expand]summary:ì˜ì–´ì›ë¬¸ ğŸ‘ˆ </p>
<p>Artificial Intelligence (AI) lies at the core of many activity sectors that have embraced new information technologies [1]. While the roots of AI trace back to several decades ago, there is a clear consensus on the paramount importance featured nowadays by intelligent machines endowed with learning, reasoning and adaptation capabilities. It is by virtue of these capabilities that AI methods are achieving unprecedented levels of performance when learning to solve increasingly complex computational tasks, making them pivotal for the future development of the human society [2]. The sophistication of AI-powered systems has lately increased to such an extent that almost no human intervention is required for their design and deployment. When decisions derived from such systems ultimately affect humansâ€™ lives (as in e.g. medicine, law or defense), there is an emerging need for understanding how such decisions are furnished by AI methods [3].</p>
<p>[/expand]</p>
<p><span style="color:#e25252">ìš”ì•½:</span> ì¸ê³µì§€ëŠ¥ì´ ì •êµí•´ì§€ë©´ì„œ ê³„ì‚°ì´ ì ì  ë³µì¡í•´ì§€ëŠ” ë°˜ë©´, ê¶ê·¹ì ìœ¼ë¡œ ì¸ê°„ì˜ ì‚¶ì— ì˜í–¥ì„ ë¯¸ì¹˜ëŠ”(ì˜í•™, ë²•ë¥ , êµ­ë°©) ì‹œìŠ¤í…œ(ê¸°ê³„)ì˜ ê²°ì •ì´ ì–´ë–»ê²Œ ë‚´ë ¤ì¡ŒëŠ”ì§€, ìš°ë¦¬ëŠ” ì´í•´í•  í•„ìš”ê°€ ìˆë‹¤.</p>
<p>[expand]summary:ì˜ì–´ì›ë¬¸ ğŸ‘ˆ </p>
<p>While the very first AI systems were easily interpretable, the last years have witnessed the rise of opaque decision systems such as Deep Neural Networks (DNNs). The empirical success of Deep Learning (DL) models such as DNNs stems from a combination of efficient learning algorithms and their huge parametric space. The latter space comprises hundreds of layers and millions of parameters, which makes DNNs be considered as complex black-box models [4]. The opposite of black-box-ness is transparency, i.e., the search for a direct understanding of the mechanism by which a model works [5].</p>
<p>[/expand]</p>
<p><span style="color:#e25252">ìš”ì•½:</span> ë”¥ëŸ¬ë‹ ëª¨ë¸ì€ íš¨ìœ¨ì ì¸ í•™ìŠµ ì•Œê³ ë¦¬ì¦˜ê³¼ ê±°ëŒ€í•œ íŒŒë¼ë¯¸í„° ê³µê°„ì˜ ê²°í•©ì—ì„œ ë¹„ë¡¯ëœë‹¤. ê·¸ë¦¬ê³  black-box ëª¨ë¸ë¡œ ê°„ì£¼ ëœë‹¤. ì´ì˜ ë°˜ëŒ€ëŠ” <strong>íˆ¬ëª…ì„±(transparency)</strong>ì´ë‹¤.</p>
<p>[expand]summary:ì˜ì–´ì›ë¬¸ ğŸ‘ˆ </p>
<p>As black-box Machine Learning (ML) models are increasingly being employed to make important predictions in critical contexts, the demand for transparency is increasing from the various stakeholders in AI [6]. The danger is on creating and using decisions that are not justifiable, legitimate, or that simply do not allow obtaining detailed explanations of their behaviour [7]. Explanations supporting the output of a model are crucial, e.g., in precision medicine, where experts require far more information from the model than a simple binary prediction for supporting their diagnosis [8]. Other examples include autonomous vehicles in transportation, security, and finance, among others.</p>
<p>[/expand]</p>
<p><span style="color:#e25252">ìš”ì•½:</span> Machine Learning ëª¨ë¸ì´ ì ì  ë§ì´ í™œìš©ë˜ë©´ì„œ, ì´í•´ê´€ê³„ìë“¤ë¡œë¶€í„° íˆ¬ëª…ì„±ì˜ ìš”êµ¬ê°€ ë†’ì•„ì§€ê³  ìˆë‹¤. ì˜ˆë¥¼ ë“¤ì–´, ì˜ë£Œ(ì§„ë‹¨), êµí†µ(ììœ¨ì£¼í–‰), ë³´ì•ˆ, ê¸ˆìœµë“± ì´ ìˆë‹¤.</p>
<p>[expand]summary:ì˜ì–´ì›ë¬¸ ğŸ‘ˆ </p>
<p>In general, humans are reticent to adopt techniques that are not directly interpretable, tractable and trustworthy [9], given the increasing demand for ethical AI [3]. It is customary to think that by focusing solely on performance, the systems will be increasingly opaque. This is true in the sense that there is a trade-off between the performance of a model and its transparency [10]. However, an improvement in the understanding of a system can lead to the correction of its deficiencies. When developing a ML model, the consideration of interpretability as an additional design driver can improve its implementability for 3 reasons:</p>
<ul>
<li>Interpretability helps ensure impartiality in decision-making, i.e. to detect, and consequently, correct from bias in the training dataset.</li>
<li>
<p>Interpretability facilitates the provision of robustness by highlighting potential adversarial perturbations that could change the prediction.</p>
</li>
<li>
<p>Interpretability can act as an insurance that only meaningful variables infer the output, i.e., guaranteeing that an underlying truthful causality exists in the model reasoning.</p>
</li>
</ul>
<p>All these means that the interpretation of the system should, in order to be considered practical, provide either an understanding of the model mechanisms and predictions, a visualization of the modelâ€™s discrimination rules, or hints on what could perturb the model [11].</p>
<p>[/expand]</p>
<p><span style="color:#e25252">ìš”ì•½:</span> í†µìƒì ìœ¼ë¡œ ì„±ê³¼ì—ë§Œ ì¹˜ì¤‘í•  ìˆ˜ë¡ ì‹œìŠ¤í…œì€ ì ì  ë¶ˆíˆ¬ëª…í•´ì§ˆ ê²ƒì´ë¼ ìƒê°í•œë‹¤. ëª¨ë¸ì˜ ì„±ëŠ¥ê³¼ íˆ¬ëª…ì„± ì‚¬ì´ì— trade-offê°€ ìˆë‹¤ëŠ” ì ì€ ì‚¬ì‹¤ì´ë‚˜, ëª¨ë¸ì— ëŒ€í•œ ì´í•´ëŠ” ëª¨ë¸ì˜ ì„±ëŠ¥ í–¥ìƒì„ ì´ëŒì–´ ë‚¼ ìˆ˜ë„ ìˆë‹¤. ì¶”ê°€ë¡œ MLëª¨ë¸ì„ ê°œë°œí•  ë•Œ, í•´ì„ ê°€ëŠ¥ì„±ì„ ëª¨ë“ˆë¡œ ë„£ìœ¼ë©´ ì„¸ ê°€ì§€ ì´ìœ ë¡œ êµ¬í˜„ ê°€ëŠ¥ì„±ì„ í–¥ìƒ ì‹œí‚¬ ìˆ˜ ìˆë‹¤.</p>
<ul>
<li>í•´ì„ê°€ëŠ¥ì„±ì€ ì˜ì‚¬ê²°ì •ì—ì„œ ê³µì •ì„±ì„ ë³´ì¥í•˜ëŠ”ë° ë„ì›€ì´ ëœë‹¤. ì¦‰, êµìœ¡ ë°ì´í„° ì§‘í•©ì˜ í¸í–¥ì„±ì„ íƒì§€í•˜ê³  ê²°ê³¼ì ìœ¼ë¡œ ìˆ˜ì •í•œë‹¤.</li>
<li>í•´ì„ê°€ëŠ¥ì„±ì€ ì˜ˆì¸¡ì„ ë°”ê¿€ ìˆ˜ ìˆëŠ” ì ì¬ì  ì ëŒ€ì  ì„­ë™ì„ ê°•ì¡°í•¨ìœ¼ë¡œì¨ ê±´ì „ì„±ì˜ ì œê³µì„ ì´‰ì§„í•œë‹¤.</li>
<li>í•´ì„ê°€ëŠ¥ì„±ì€ ìœ ì˜ë¯¸í•œ ë³€ìˆ˜ë§Œìœ¼ë¡œ ì‚°ì¶œë¬¼ì„ ìœ ì¶”í•˜ëŠ” ë³´í—˜ìœ¼ë¡œì„œ, ì¦‰ ëª¨í˜• ì¶”ë¡ ì—ì„œ ê·¼ë³¸ì ì¸ ì§„ì‹¤ì  ì¸ê³¼ê´€ê³„ê°€ ì¡´ì¬í•¨ì„ ë³´ì¦í•˜ëŠ” ë³´í—˜ìœ¼ë¡œ ì‘ìš©í•  ìˆ˜ ìˆë‹¤.</li>
</ul>
<p>ì¦‰, í•´ì„ê°€ëŠ¥í•œ ì‹œìŠ¤í…œì€ ëª¨ë¸ ë§¤ì»¤ë‹ˆì¦˜ê³¼ ì˜ˆì¸¡ì— ëŒ€í•œ ì´í•´, ëª¨ë¸ì˜ íŒê²° ê·œì¹™ ì‹œê°í™”, ë˜ëŠ” ëª¨ë¸ì„ ë°©í•´í•˜ëŠ” ê²ƒì— ëŒ€í•œ íŒíŠ¸ ë“±ì„ ì œê³µí•´ì•¼í•œë‹¤.</p>
<p>[expand]summary:ì˜ì–´ì›ë¬¸ ğŸ‘ˆ </p>
<p>In order to avoid limiting the effectiveness of the current generation of AI systems, eXplainable AI (XAI) [7] proposes creating a suite of ML techniques that 1) produce more explainable models while maintaining a high level of learning performance (e.g., prediction accuracy), and 2) enable humans to understand, appropriately trust, and effectively manage the emerging generation of artificially intelligent partners. XAI draws as well insights from the Social Sciences [12] and considers the psychology of explanation.</p>
<p>[/expand]</p>
<p><span style="color:#e25252">ìš”ì•½:</span> í˜„ì¬ì˜ íš¨ê³¼ì ì¸ AI ì‹œìŠ¤í…œì„ ì œí•œì‹œí‚¤ì§€ ì•ŠëŠ” ì„ ì—ì„œ, eXplainable AI(XAI)ì€ 1) í•™ìŠµ í¼í¬ë¨¼ìŠ¤ëŠ” ìµœëŒ€í•œìœ¼ë¡œ ìœ ì§€í•˜ë©´ì„œ ì„¤ëª…ê°€ëŠ¥í•œ ëª¨ë¸ì„ ë§Œë“¤ê²ƒì„ ì œì•ˆ 2) ì‚¬ëŒì´ ì´í•´í•˜ê³ , ì ì ˆí•˜ê³  íš¨ê³¼ì ìœ¼ë¡œ ì‹ ë¢°í•  ìˆ˜ ìˆë„ë¡ í•œë‹¤.</p>
<p>[expand]summary:ì˜ì–´ì›ë¬¸ ğŸ‘ˆ </p>
<p>Fig. 1 displays the rising trend of contributions on XAI and related concepts. This literature outbreak shares its rationale with the research agendas of national governments and agencies. Although some recent surveys [8], [10], [13], [14], [15], [16], [17] summarize the upsurge of activity in XAI across sectors and disciplines, this overview aims to cover the creation of a complete unified framework of categories and concepts that allow for scrutiny and understanding of the field of XAI methods. Furthermore, we pose intriguing thoughts around the explainability of AI models in data fusion contexts with regards to data privacy and model confidentiality. This, along with other research opportunities and challenges identified throughout our study, serve as the pull factor toward Responsible Artificial Intelligence, term by which we refer to a series of AI principles to be necessarily met when deploying AI in real applications. As we will later show in detail, model explainability is among the most crucial aspects to be ensured within this methodological framework. All in all, the novel contributions of this overview can be summarized as follows:</p>
<ol>
<li>Grounded on a first elaboration of concepts and terms used in XAI-related research, we propose a novel definition of explainability that places audience (Fig. 2) as a key aspect to be considered when explaining a ML model. We also elaborate on the diverse purposes sought when using XAI techniques, from trustworthiness to privacy awareness, which round up the claimed importance of purpose and targeted audience in model explainability.</li>
<li>We define and examine the different levels of transparency that a ML model can feature by itself, as well as the diverse approaches to post-hoc explainability, namely, the explanation of ML models that are not transparent by design.</li>
<li>We thoroughly analyze the literature on XAI and related concepts published to date, covering approximately 400 contributions arranged into two different taxonomies. The first taxonomy addresses the explainability of ML models using the previously made distinction between transparency and post-hoc explainability, including models that are transparent by themselves, Deep and non-Deep (i.e., shallow) learning models. The second taxonomy deals with XAI methods suited for the explanation of Deep Learning models, using classification criteria closely linked to this family of ML methods (e.g. layerwise explanations, representation vectors, attention).</li>
<li>We enumerate a series of challenges of XAI that still remain insufficiently addressed to date. Specifically, we identify research needs around the concepts and metrics to evaluate the explainability of ML models, and outline research directions toward making Deep Learning models more understandable. We further augment the scope of our prospects toward the implications of XAI techniques in regards to confidentiality, robustness in adversarial settings, data diversity, and other areas intersecting with explainability.</li>
<li>After the previous prospective discussion, we arrive at the concept of Responsible Artificial Intelligence, a manifold concept that imposes the systematic adoption of several AI principles for AI models to be of practical use. In addition to explainability, the guidelines behind Responsible AI establish that fairness, accountability and privacy should also be considered when implementing AI models in real environments.</li>
<li>Since Responsible AI blends together model explainability and privacy/security by design, we call for a profound reflection around the benefits and risks of XAI techniques in scenarios dealing with sensitive information and/or confidential ML models. As we will later show, the regulatory push toward data privacy, quality, integrity and governance demands more efforts to assess the role of XAI in this arena. In this regard, we provide an insight on the implications of XAI in terms of privacy and security under different data fusion paradigms.</li>
</ol>
<p>[/expand]</p>
<p>{% include image.html id="119QnRBvYV4gHiuKz7kpaOVo_2b2tlhz5" desc="Fig 1. í•™ê³„ì—ì„œ XAI ë° ì—°ê´€ëœ ê°œë…ì˜ ê¸°ì—¬ë„ ì¶”ì„¸" width="100%" height="auto" %}</p>
<p><span style="color:#e25252">ìš”ì•½:</span> <code>Fig 1</code>ì—ì„œ ë³¼ ìˆ˜ ìˆë“¯ì´ êµ­ê°€ ì •ë¶€ ë° ê¸°ê´€ì˜ ì—°êµ¬ì˜ì œì˜ í‚¤ì›Œë“œ ì¶”ì„¸ë¥¼ ì‚´í´ë³´ë©´ XAIê´€ë ¨ í™œë™ì´ ìµœê·¼ ê¸‰ì¦í–ˆì§€ë§Œ, í†µì¼ëœ í”„ë ˆì„ì›Œí¬ê°€ ì—†ë‹¤. ì´ë²ˆ ë…¼ë¬¸ì—ì„œëŠ” í†µì¼ëœ í”„ë ˆì„ì›Œí¬ì˜ ì‘ì„±í•˜ê³ , ê°œì¸ì •ë³´ ë³´í˜¸ ë° ëª¨ë¸ ê¸°ë°€ì„±ì— ëŒ€í•´ì„œ ì˜ê²¬ì„ ì œì‹œí•  ê²ƒì´ë‹¤. </p>
<ol>
<li>ì§€ê¸ˆê¹Œì§€ XAI ê´€ë ¨ ì—°êµ¬ì—ì„œ ì‚¬ìš©ëœ ê°œë…ê³¼ ìš©ì–´ì˜ ê¸°ì´ˆí•˜ì—¬, ML ëª¨ë¸ì„ ì„¤ëª…í•  ë•Œ ì²­ì¤‘(audience)ì„ í•µì‹¬ìœ¼ë¡œ ê³ ë ¤í•  ê²ƒì´ë‹¤(ê·¸ë¦¼ 2). ë˜í•œ XAI ê¸°ë²•ì„ ì‚¬ìš©í•  ë•Œ ì¶”êµ¬í•˜ëŠ” ë‹¤ì–‘í•œ ëª©ì ì— ë”°ë¼ ì„¸ë¶„í™”í•  ê²ƒì´ë‹¤. ê·¸ë¦¬ê³  ì„¤ëª…ê°€ëŠ¥ì„±ì—ì„œ ëª©ì ê³¼ íƒ€ê²Ÿ ì²­ì¤‘ì˜ ì¤‘ìš”í•¨ì„ ì´ì•¼ê¸° í•œë‹¤.</li>
<li>ë‹¤ì–‘í•œ ë ˆë²¨ì˜ íˆ¬ëª…ì„±ì„ ì •ì˜í•˜ê³  ê²€í† í•œë‹¤. ëŒ€ìƒì—ëŠ” ì‚¬í›„(post-hoc) ì„¤ëª…ì´ ê°€ëŠ¥í•œ, ìì²´ ì„¤ëª…ê°€ëŠ¥í•œ í˜¹ì€ ì„¤ê³„ì— ì˜í•´ ì„¤ëª…ì´ ë¶ˆê°€ëŠ¥í•œ ëª¨ë¸ë“¤ ë“±ì´ ìˆë‹¤.</li>
<li>XAIì— ê´€í•œ ë¬¸í—Œê³¼ ì§€ê¸ˆê¹Œì§€ ì¶œíŒëœ ê´€ë ¨ ê°œë…ë“¤ì„ ì² ì €í•˜ê²Œ ë¶„ì„í•˜ì—¬, ëŒ€ëµ 400ê°œì˜ ê¸°ì—¬ë¥¼ ë‘ ê°œì˜ ë‹¤ë¥¸ ë¶„ë¥˜ë²•ìœ¼ë¡œ ë°°ì—´í•˜ì˜€ë‹¤.Â ì²« ë²ˆì§¸ ë¶„ë¥˜ë²•ì€ ì´ì „ì— ë§Œë“  íˆ¬ëª…ì„±(transparency)ê³¼ ì‚¬í›„ ì„¤ëª…ì„±(post-hoc explainability) ì‚¬ì´ì˜ êµ¬ë³„ì„ ì‚¬ìš©í•˜ì—¬ ML ëª¨ë¸ì˜ ì„¤ëª…ê°€ëŠ¥ì„±ì„ ë‹¤ë£¨ê³  ìˆìœ¼ë©°, ì—¬ê¸°ì—ëŠ” ìŠ¤ìŠ¤ë¡œ íˆ¬ëª…í•˜ê³  ê¹Šì§€ ì•Šì€(ì¦‰,Â shallow ì–‰ì€) í•™ìŠµ ëª¨ë¸ì´ í¬í•¨ëœë‹¤.Â ë‘ ë²ˆì§¸ ë¶„ë¥˜ë²•ì€ ë”¥ëŸ¬ë‹ ëª¨ë¸ì˜ ì„¤ëª…ì— ì í•©í•œ XAI ë°©ë²•ì„ ë‹¤ë£¨ë©°, ì´ ML ë°©ë²• ê³„ì—´ê³¼ ë°€ì ‘í•˜ê²Œ ì—°ê³„ëœ ë¶„ë¥˜ ê¸°ì¤€(ì˜ˆ: ê³„ì¸µì  ì„¤ëª… layer-wise explanations, í‘œí˜„ ë²¡í„° representation vectors, ì–´í…ì…˜ attention)ì„ ì‚¬ìš©í•œë‹¤.</li>
<li>ì§€ê¸ˆê¹Œì§€ë„ ë¶ˆì¶©ë¶„í•˜ê²Œ ë‹¤ë£¨ì–´ì§€ì§€ ì•Šê³  ìˆëŠ” XAIì˜ ì¼ë ¨ì˜ ê³¼ì œë¥¼ ì—´ê±°í•œë‹¤.Â êµ¬ì²´ì ìœ¼ë¡œëŠ” ML ëª¨ë¸ì˜ ì„¤ëª… ê°€ëŠ¥ì„±ì„ í‰ê°€í•˜ê¸° ìœ„í•´ ê°œë… ë° ë©”íŠ¸ë¦­ìŠ¤ë¥¼ ì¤‘ì‹¬ìœ¼ë¡œ ì—°êµ¬ ìš”êµ¬ë¥¼ íŒŒì•…í•˜ê³ , ë”¥ëŸ¬ë‹ ëª¨ë¸ì„ ë³´ë‹¤ ì´í•´í•  ìˆ˜ ìˆë„ë¡ ì—°êµ¬ ë°©í–¥ì„ ì •ë¦¬í•œë‹¤.Â ê¸°ë°€ì„±, ì ëŒ€ì  ì„¤ì •ì˜ ê²¬ê³ ì„±, ë°ì´í„° ë‹¤ì–‘ì„± ë° ì„¤ëª… ê°€ëŠ¥ì„±ê³¼ êµì°¨í•˜ëŠ” ê¸°íƒ€ ì˜ì—­ì— ê´€í•œ XAI ê¸°ë²•ì˜ í•¨ì¶•ì„±ì„ í–¥í•œ ì „ë§ì˜ ë²”ìœ„ë¥¼ ë”ìš± í™•ëŒ€í•©ë‹ˆë‹¤.</li>
<li>ì•ì„œì˜ ì¥ë˜ì˜ ë…¼ì˜ë¥¼ ê±°ì³, AI ëª¨ë¸ì´ ì‹¤ìš©í™”í•˜ê¸° ìœ„í•´ ì—¬ëŸ¬ ê°€ì§€ AI ì›ë¦¬ë¥¼ ì²´ê³„ì ìœ¼ë¡œ ì±„íƒí•˜ëŠ” ë§¤ë‹ˆí´ë“œ ê°œë…ì¸ ì±…ì„ê° ìˆëŠ” ì¸ê³µì§€ëŠ¥ì˜ ê°œë…ì— ë„ë‹¬í•œë‹¤.Â ì±…ì„ AIë¥¼ ë’·ë°›ì¹¨í•˜ëŠ” ê°€ì´ë“œë¼ì¸ì€ ì„¤ëª…ê°€ëŠ¥ì„± ì™¸ì—ë„ ì‹¤ì œ í™˜ê²½ì—ì„œ AI ëª¨ë¸ì„ êµ¬í˜„í•  ë•Œ ê³µì •ì„±, ì±…ì„ì„±, í”„ë¼ì´ë²„ì‹œ ë“±ë„ ê³ ë ¤í•´ì•¼ í•œë‹¤ê³  ê·œì •í•˜ê³  ìˆë‹¤.</li>
<li>ì±…ì„ ìˆëŠ” AIëŠ” ëª¨ë¸ ì„¤ëª… ê°€ëŠ¥ì„±ê³¼ ê°œì¸ ì •ë³´ ë³´í˜¸/ë³´ì•ˆì„±ì„ ì„¤ê³„ë³„ë¡œ í˜¼í•©í•˜ë¯€ë¡œ, ë¯¼ê°í•œ ì •ë³´ ë°/ë˜ëŠ” ê¸°ë°€ ML ëª¨ë¸ì„ ë‹¤ë£¨ëŠ” ì‹œë‚˜ë¦¬ì˜¤ì—ì„œ XAI ê¸°ë²•ì˜ ìœ ìµì„±ê³¼ ìœ„í•´ì„±ì— ëŒ€í•´ ì‹¬ì˜¤í•œ ë°˜ì„±ì„ ìš”êµ¬í•œë‹¤.Â ë‚˜ì¤‘ì— ë³´ì—¬ë“œë¦¬ê² ì§€ë§Œ, ë°ì´í„° ê°œì¸ ì •ë³´ ë³´í˜¸, í’ˆì§ˆ, ë¬´ê²°ì„± ë° ê±°ë²„ë„ŒìŠ¤ë¥¼ í–¥í•œ ê·œì œëŠ” ì´ ë¶„ì•¼ì—ì„œ XAIì˜ ì—­í• ì„ í‰ê°€í•˜ê¸° ìœ„í•œ ë” ë§ì€ ë…¸ë ¥ì„ ìš”êµ¬í•©ë‹ˆë‹¤.Â ì´ì™€ ê´€ë ¨í•˜ì—¬, ìš°ë¦¬ëŠ” ì„œë¡œ ë‹¤ë¥¸ ë°ì´í„° ìœµí•© íŒ¨ëŸ¬ë‹¤ì„ í•˜ì—ì„œì˜ í”„ë¼ì´ë²„ì‹œ ë° ë³´ì•ˆ ì¸¡ë©´ì—ì„œ XAIì˜ ì˜ë¯¸ì— ëŒ€í•œ í†µì°°ë ¥ì„ ì œê³µí•œë‹¤.</li>
</ol>
<p>[expand]summary:ì˜ì–´ì›ë¬¸ ğŸ‘ˆ </p>
<p>The remainder of this overview is structured as follows: first, Section 2 and subsections therein open a discussion on the terminology and concepts revolving around explainability and interpretability in AI, ending up with the aforementioned novel definition of interpretability (Section 2.1 and 2.2), and a general criterion to categorize and analyze ML models from the XAI perspective. Sections 3 and 4 proceed by reviewing recent findings on XAI for ML models (on transparent models and post-hoc techniques respectively) that comprise the main division in the aforementioned taxonomy. We also include a review on hybrid approaches among the two, to attain XAI. Benefits and caveats of the synergies among the families of methods are discussed in Section 5, where we present a prospect of general challenges and some consequences to be cautious about. Finally, Section 6 elaborates on the concept of Responsible Artificial Intelligence. Section 7 concludes the survey with an outlook aimed at engaging the community around this vibrant research area, which has the potential to impact society, in particular those sectors that have progressively embraced ML as a core technology of their activity.</p>
<p>[/expand]</p>
<p><span style="color:#e25252">ìš”ì•½:</span> ë‚˜ë¨¸ì§€ ë¶€ë¶„ì€ ë‹¤ìŒê³¼ ê°™ì´ êµ¬ì„±ë˜ì–´ ìˆë‹¤: </p>
<ul>
<li>Section 2: ì„¤ëª…ê°€ëŠ¥ì„±(explainability)ì™€ í•´ì„ê°€ëŠ¥ì„±(interpretability)ì˜ ìƒˆë¡œìš´ ì •ì˜, XAI ê´€ì ì—ì„œ ML ëª¨ë¸ ë¶„ë¥˜ ë° ë¶„ì„ì„ ìœ„í•œ ìš©ì–´ ë° ê°œë…ì— ëŒ€í•œ ì´ì•¼ê¸°</li>
<li>Section 3, 4: ìµœê·¼ ì—°êµ¬ ê²°ê³¼ì™€ í•˜ì´ë¸Œë¦¬ë“œ ë°©ë²•</li>
<li>Section 5: í•´ë‹¹ ë°©ë²•ë“¤ì— ëŒ€í•œ ì¥ë‹¨ì  ë° ì£¼ì˜í•´ì•¼í•  ëª‡ ê°€ì§€ ê²°ê³¼ë“¤ ì œì‹œ</li>
<li>Section 6: "ì±…ì„ê° ìˆëŠ” ì¸ê³µì§€ëŠ¥" ê°œë…ì— ëŒ€í•œ ì„¤ëª…</li>
<li>Section 7: ì‚¬íšŒì— ì˜í–¥ì„ ë¯¸ì¹  ê°€ëŠ¥ì„±ì´ ìˆëŠ” ì—°êµ¬ ì˜ì—­ì¸ ë§Œí¼, ML ê¸°ìˆ ì„ ì±„íƒí•œ ì‚¬ëŒë“¤ì„ ì»¤ë®¤ë‹ˆí‹°ë¥¼ ì°¸ì—¬ì‹œí‚¤ëŠ” ëª©í‘œë¡œ ê²°ë¡ ì„ ë‚´ë¦¬ê³ ì í•œë‹¤.</li>
</ul>

              

  <!-- Giscus -->
  <h2 id="__comments">Comments</h2>
  <script src="https://utteranc.es/client.js"
        repo="simonjisu/utterances_comments"
        issue-term="pathname"
        theme="github-light"
        crossorigin="anonymous"
        async>
  </script>

  <!-- Reload on palette change -->
  <script>
    var palette = __md_get("__palette")
    if (palette && typeof palette.color === "object")
      if (palette.color.scheme === "slate") {
        var giscus = document.querySelector("script[src*=giscus]")
        giscus.setAttribute("data-theme", "dark") 
      }

    /* Register event handlers after documented loaded */
    document.addEventListener("DOMContentLoaded", function() {
      var ref = document.querySelector("[data-md-component=palette]")
      ref.addEventListener("change", function() {
        var palette = __md_get("__palette")
        if (palette && typeof palette.color === "object") {
          var theme = palette.color.scheme === "slate" ? "dark" : "light"

          /* Instruct Giscus to change theme */
          var frame = document.querySelector(".giscus-frame")
          frame.contentWindow.postMessage(
            { giscus: { setConfig: { theme } } },
            "https://giscus.app"
          )
        }
      })
    })
  </script>

            </article>
            
          </div>
        </div>
        
      </main>
      
        <footer class="md-footer">
  
    
    <nav class="md-footer__inner md-grid" aria-label="Footer" >
      
        
        <a href="../2020-07-23-casm/" class="md-footer__link md-footer__link--prev" aria-label="Previous: Classifier-agnostic saliency map extraction" rel="prev">
          <div class="md-footer__button md-icon">
            <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M20 11v2H8l5.5 5.5-1.42 1.42L4.16 12l7.92-7.92L13.5 5.5 8 11h12Z"/></svg>
          </div>
          <div class="md-footer__title">
            <div class="md-ellipsis">
              <span class="md-footer__direction">
                Previous
              </span>
              Classifier-agnostic saliency map extraction
            </div>
          </div>
        </a>
      
      
        
        <a href="../2021-01-14-xaitutorial2/" class="md-footer__link md-footer__link--next" aria-label="Next: Explainable Artificial Intelligence (XAI) - 2" rel="next">
          <div class="md-footer__title">
            <div class="md-ellipsis">
              <span class="md-footer__direction">
                Next
              </span>
              Explainable Artificial Intelligence (XAI) - 2
            </div>
          </div>
          <div class="md-footer__button md-icon">
            <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M4 11v2h12l-5.5 5.5 1.42 1.42L19.84 12l-7.92-7.92L10.5 5.5 16 11H4Z"/></svg>
          </div>
        </a>
      
    </nav>
  
  <div class="md-footer-meta md-typeset">
    <div class="md-footer-meta__inner md-grid">
      <div class="md-copyright">
  
  
    Made with
    <a href="https://squidfunk.github.io/mkdocs-material/" target="_blank" rel="noopener">
      Material for MkDocs
    </a>
  
</div>
      
        <div class="md-social">
  
    
    
      
      
    
    <a href="https://github.com/simonjisu" target="_blank" rel="noopener" title="github.com" class="md-social__link">
      <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 496 512"><!--! Font Awesome Free 6.1.1 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free (Icons: CC BY 4.0, Fonts: SIL OFL 1.1, Code: MIT License) Copyright 2022 Fonticons, Inc.--><path d="M165.9 397.4c0 2-2.3 3.6-5.2 3.6-3.3.3-5.6-1.3-5.6-3.6 0-2 2.3-3.6 5.2-3.6 3-.3 5.6 1.3 5.6 3.6zm-31.1-4.5c-.7 2 1.3 4.3 4.3 4.9 2.6 1 5.6 0 6.2-2s-1.3-4.3-4.3-5.2c-2.6-.7-5.5.3-6.2 2.3zm44.2-1.7c-2.9.7-4.9 2.6-4.6 4.9.3 2 2.9 3.3 5.9 2.6 2.9-.7 4.9-2.6 4.6-4.6-.3-1.9-3-3.2-5.9-2.9zM244.8 8C106.1 8 0 113.3 0 252c0 110.9 69.8 205.8 169.5 239.2 12.8 2.3 17.3-5.6 17.3-12.1 0-6.2-.3-40.4-.3-61.4 0 0-70 15-84.7-29.8 0 0-11.4-29.1-27.8-36.6 0 0-22.9-15.7 1.6-15.4 0 0 24.9 2 38.6 25.8 21.9 38.6 58.6 27.5 72.9 20.9 2.3-16 8.8-27.1 16-33.7-55.9-6.2-112.3-14.3-112.3-110.5 0-27.5 7.6-41.3 23.6-58.9-2.6-6.5-11.1-33.3 2.6-67.9 20.9-6.5 69 27 69 27 20-5.6 41.5-8.5 62.8-8.5s42.8 2.9 62.8 8.5c0 0 48.1-33.6 69-27 13.7 34.7 5.2 61.4 2.6 67.9 16 17.7 25.8 31.5 25.8 58.9 0 96.5-58.9 104.2-114.8 110.5 9.2 7.9 17 22.9 17 46.4 0 33.7-.3 75.4-.3 83.6 0 6.5 4.6 14.4 17.3 12.1C428.2 457.8 496 362.9 496 252 496 113.3 383.5 8 244.8 8zM97.2 352.9c-1.3 1-1 3.3.7 5.2 1.6 1.6 3.9 2.3 5.2 1 1.3-1 1-3.3-.7-5.2-1.6-1.6-3.9-2.3-5.2-1zm-10.8-8.1c-.7 1.3.3 2.9 2.3 3.9 1.6 1 3.6.7 4.3-.7.7-1.3-.3-2.9-2.3-3.9-2-.6-3.6-.3-4.3.7zm32.4 35.6c-1.6 1.3-1 4.3 1.3 6.2 2.3 2.3 5.2 2.6 6.5 1 1.3-1.3.7-4.3-1.3-6.2-2.2-2.3-5.2-2.6-6.5-1zm-11.4-14.7c-1.6 1-1.6 3.6 0 5.9 1.6 2.3 4.3 3.3 5.6 2.3 1.6-1.3 1.6-3.9 0-6.2-1.4-2.3-4-3.3-5.6-2z"/></svg>
    </a>
  
</div>
      
    </div>
  </div>
</footer>
      
    </div>
    <div class="md-dialog" data-md-component="dialog">
      <div class="md-dialog__inner md-typeset"></div>
    </div>
    <script id="__config" type="application/json">{"base": "../..", "features": ["navigation.prune", "toc.follow"], "search": "../../assets/javascripts/workers/search.b97dbffb.min.js", "translations": {"clipboard.copied": "Copied to clipboard", "clipboard.copy": "Copy to clipboard", "search.config.lang": "en", "search.config.pipeline": "trimmer, stopWordFilter", "search.config.separator": "[\\s\\-]+", "search.placeholder": "Search", "search.result.more.one": "1 more on this page", "search.result.more.other": "# more on this page", "search.result.none": "No matching documents", "search.result.one": "1 matching document", "search.result.other": "# matching documents", "search.result.placeholder": "Type to start searching", "search.result.term.missing": "Missing", "select.version.title": "Select version"}}</script>
    
    
      <script src="../../assets/javascripts/bundle.6c7ad80a.min.js"></script>
      
        <script src="../../javascripts/mathjax.js"></script>
      
        <script src="https://polyfill.io/v3/polyfill.min.js?features=es6"></script>
      
        <script src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>
      
    
  </body>
</html>